# Business Analyst Backend API

Backend API para el chatbot Business Analyst con integraciÃ³n de LLMs usando LangChain.

## ğŸš€ CaracterÃ­sticas

- **FastAPI**: Framework web moderno y rÃ¡pido
- **LangChain**: IntegraciÃ³n con mÃºltiples LLMs
- **Groq & OpenAI**: Soporte para ambos proveedores
- **SQLAlchemy**: ORM para base de datos
- **Pydantic**: ValidaciÃ³n de datos
- **CORS**: Configurado para frontend NextJS

## ğŸ› ï¸ TecnologÃ­as

- **Python 3.8+**
- **FastAPI** - Framework web
- **LangChain** - IntegraciÃ³n con LLMs
- **SQLAlchemy** - ORM
- **Pydantic** - ValidaciÃ³n de datos
- **SQLite/PostgreSQL** - Base de datos

## ğŸ“¦ InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone <repository-url>
cd ba-backend
```

2. **Crear entorno virtual:**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **Instalar dependencias:**

**OpciÃ³n 1 - InstalaciÃ³n simple (recomendada):**
```bash
pip install -r requirements-simple.txt
```

**OpciÃ³n 2 - InstalaciÃ³n robusta (si hay conflictos):**
```bash
# Windows
install-clean.bat

# Linux/Mac
chmod +x install.sh
./install.sh
```

**OpciÃ³n 3 - CorrecciÃ³n rÃ¡pida de importaciones:**
```bash
# Si hay errores de importaciÃ³n
fix_imports.bat
```

**OpciÃ³n 4 - InstalaciÃ³n manual:**
```bash
pip install fastapi uvicorn python-multipart pydantic pydantic-settings python-dotenv sqlalchemy structlog
pip install langchain langchain-community langchain-groq langchain-openai
pip install httpx alembic
```

4. **Configurar variables de entorno:**
```bash
cp env.example .env
```

Edita `.env` con tu configuraciÃ³n:
```env
# LLM Configuration
GROQ_API_KEY=tu_groq_api_key
OPENAI_API_KEY=tu_openai_api_key
DEFAULT_LLM_PROVIDER=groq

# CORS
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
```

5. **Ejecutar el servidor:**
```bash
python main.py
```

El servidor estarÃ¡ disponible en `http://localhost:8000`

## ğŸ”Œ Endpoints de la API

### AutenticaciÃ³n
- `POST /auth/device/init` - Inicializar dispositivo

### Chat
- `POST /chat/stream` - Procesar mensaje del chat

### Briefs
- `POST /brief/save` - Guardar brief del proyecto
- `GET /brief/{brief_id}` - Obtener brief por ID

### Leads
- `POST /leads/create` - Crear lead
- `GET /leads/{lead_id}` - Obtener lead por ID

## ğŸ¤– ConfiguraciÃ³n de LLMs

### Groq
1. ObtÃ©n tu API key en [Groq Console](https://console.groq.com/)
2. Configura `GROQ_API_KEY` en `.env`
3. Establece `DEFAULT_LLM_PROVIDER=groq`

### OpenAI
1. ObtÃ©n tu API key en [OpenAI Platform](https://platform.openai.com/)
2. Configura `OPENAI_API_KEY` en `.env`
3. Establece `DEFAULT_LLM_PROVIDER=openai`

## ğŸ—ï¸ Estructura del Proyecto

```
ba-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                 # Endpoints de la API
â”‚   â”‚   â”œâ”€â”€ auth.py         # AutenticaciÃ³n
â”‚   â”‚   â”œâ”€â”€ chat.py         # Chat con LLM
â”‚   â”‚   â”œâ”€â”€ brief.py        # GestiÃ³n de briefs
â”‚   â”‚   â””â”€â”€ leads.py        # GestiÃ³n de leads
â”‚   â”œâ”€â”€ core/               # ConfiguraciÃ³n central
â”‚   â”‚   â”œâ”€â”€ config.py       # ConfiguraciÃ³n
â”‚   â”‚   â”œâ”€â”€ database.py     # Base de datos
â”‚   â”‚   â””â”€â”€ logging.py      # Logging
â”‚   â”œâ”€â”€ models/             # Modelos de base de datos
â”‚   â”‚   â”œâ”€â”€ brief.py        # Modelo de brief
â”‚   â”‚   â”œâ”€â”€ chat.py         # Modelo de chat
â”‚   â”‚   â””â”€â”€ lead.py         # Modelo de lead
â”‚   â”œâ”€â”€ schemas/            # Esquemas Pydantic
â”‚   â”‚   â”œâ”€â”€ brief.py        # Esquemas de brief
â”‚   â”‚   â”œâ”€â”€ chat.py         # Esquemas de chat
â”‚   â”‚   â””â”€â”€ lead.py         # Esquemas de lead
â”‚   â””â”€â”€ services/           # Servicios de negocio
â”‚       â””â”€â”€ llm_service.py  # Servicio de LLM
â”œâ”€â”€ main.py                 # Punto de entrada
â”œâ”€â”€ requirements.txt        # Dependencias
â””â”€â”€ README.md              # DocumentaciÃ³n
```

## ğŸ”§ Desarrollo

### Ejecutar en modo desarrollo
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### DocumentaciÃ³n de la API
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### Logs
Los logs se generan en formato JSON estructurado usando `structlog`.

## ğŸš€ Despliegue

### Docker
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Variables de Entorno de ProducciÃ³n
```env
DEBUG=false
DATABASE_URL=postgresql://user:password@localhost/business_analyst
SECRET_KEY=your-production-secret-key
ALLOWED_ORIGINS=https://yourdomain.com
```

## ğŸ“ Variables de Entorno

| Variable | DescripciÃ³n | Valor por defecto |
|----------|-------------|-------------------|
| `GROQ_API_KEY` | API key de Groq | - |
| `OPENAI_API_KEY` | API key de OpenAI | - |
| `DEFAULT_LLM_PROVIDER` | Proveedor por defecto | `groq` |
| `DATABASE_URL` | URL de base de datos | `sqlite:///./business_analyst.db` |
| `ALLOWED_ORIGINS` | URLs permitidas para CORS | `http://localhost:3000` |

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.
